library(lmtest)

# CASE
# Predicting baseball batting average
# The objective of this exercise will be to predict 
# a player’s batting average in a given year

# A sample of major league baseball players was obtained.
# The following data (X1, X2, X3, X4, X5, X6) are by player.
# Y = batting average
# X1 = runs scored/times at bat
# X2 = doubles/times at bat
# X3 = triples/times at bat
# X4 = home runs/times at bat
# X5 = strike outs/times at bat

baseball <- read.delim(file = "bsbl.txt", header = TRUE, sep = "\t", dec = ",")

# FILE -> REOPEN WITH ENCODING -> UTF-8
# For ukrainian

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

## Завдання (А)
## Y^= b0 + b1x1 + b2x2 + b3x3 + b4x4 + b5x5 
## Перевірити дані на лінійність. Представити графічно plot(*, 1).
## Вказати які змінні потребують корекції.

#----------------------------------------------------------------------------------------------------------------

#Лінійність

car::scatterplotMatrix(~ Y+X1+X2+X3+X4+X5,col = 1, regLine = list(col = 2),
                       smooth = list(col.smooth = 4, col.spread = 4),data = baseball)

# З графіка бачимо, що гарна лінійна залежність простежується
# між змінними X1 та Y.
# Найменший лінійний зв'язок на перший погляд у X4 та Y.

#----------------------------------------------------------------------------------------------------------------

# Повна лінійна модель
mod <- lm(Y~.,data = baseball)
summary(mod)
# Multiple R-squared:  0.8646,	Adjusted R-squared:  0.8472 
# F-statistic:  49.8 on 5 and 39 DF,  p-value: 6.75e-16

#----------------------------------------------------------------------------------------------------------------

# Тепер утворимо напівлогарифмічну модель
# Тобто в самій базі з'явилася колонка y
baseball$y <- log(baseball$Y)

# Побудуємо знов модель
# Прибираємо попередню змінну Y
mod_worse <- lm(y~.-Y, data=baseball)
summary(mod_worse)
# Multiple R-squared:  0.8579,	Adjusted R-squared:  0.8397 
# F-statistic: 47.09 on 5 and 39 DF,  p-value: 1.71e-15

#Бачимо, що модель краще не стала, а навіть погіршилася

#----------------------------------------------------------------------------------------------------------------

# Побудуємо таку модель
baseball$y1 <- sqrt(baseball$Y)
mod1 <- lm(y1~.-Y-y, data=baseball)
summary(mod1)
# Multiple R-squared:  0.8628,	Adjusted R-squared:  0.8452 
# F-statistic: 49.04 on 5 and 39 DF,  p-value: 8.723e-16

#Бачимо, що модель стала трохи кращою, ніж попередня, але не на багато.

#----------------------------------------------------------------------------------------------------------------

mod2 <- lm(Y ~ X1+I(log(X2))+X3+X4+X5, data = baseball)
summary(mod2)
# Multiple R-squared:  0.8651,	Adjusted R-squared:  0.8477 
# F-statistic:    50 on 5 and 39 DF,  p-value: 6.319e-16

#Знову трохи покращилася F-statistic

#----------------------------------------------------------------------------------------------------------------

# Найкраща модель після перетворень
mod_better <- lm(Y ~ X1+I(log(X2))+I(log(X3))+I(sqrt(X4))+X5, data = baseball)
summary(mod_better)
# Multiple R-squared:  0.8673,	Adjusted R-squared:  0.8503 
# F-statistic: 50.96 on 5 and 39 DF,  p-value: 4.591e-16

#----------------------------------------------------------------------------------------------------------------

#Відкинемо X4
mod_better1 <- lm(Y ~ X1+I(log(X2))+I(log(X3))+X5, data = baseball)
summary(mod_better1)
# Multiple R-squared:  0.8638,	Adjusted R-squared:  0.8502 
# F-statistic: 63.43 on 4 and 40 DF,  p-value: < 2.2e-16

# Модель набагато покращилася

#----------------------------------------------------------------------------------------------------------------

# Очищені моделі

modBIC <- MASS::stepAIC(mod, k = log(nrow(baseball)))
summary(modBIC)
# Multiple R-squared:  0.8602,	Adjusted R-squared:  0.8499 
# F-statistic: 84.06 on 3 and 41 DF,  p-value: < 2.2e-16

#----------------------------------------------------------------------------------------------------------------

modBIC1 <- MASS::stepAIC(mod_better, k = log(nrow(baseball)))
summary(modBIC1)
# Multiple R-squared:  0.8611,	Adjusted R-squared:  0.8509 
# F-statistic: 84.73 on 3 and 41 DF,  p-value: < 2.2e-16

# modBIC1 - найкраща модель, з показником F-statistic: 84.73

# Висновок: 
# Тож змінні, що потребують корекції - X3,X4
# Алгоритм MASS::stepAIC очистив саме ці змінні
# Прибираючи чи перетворюючи їх, модель покращується
# Також заміна X2 дає свої результати
# А змінні X1, X5 краще взагалі не чіпати.

#----------------------------------------------------------------------------------------------------------------

#Будуємо графіки
par(mfrow = c(1,1))
plot(mod, 1)
plot(mod_better, 1)
plot(mod_better1, 1)
plot(modBIC1, 1)

# З графіку бачимо, що червона лінія максимально наближена 
# до горизонтальної лінії в modBIC1,
# що є гарним показником.

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

## Завдання (B)
# Перевірити дані на нормальність. 
# Представити графічно plot(*, 2).
# Для перевірки використати тести Шапіро-Вілька та Лілліфорса;

#----------------------------------------------------------------------------------------------------------------

par(mfrow = c(1, 2))
plot(mod, 2)
plot(mod_better, 2)
plot(mod_better1, 2)
plot(modBIC1, 2)
#Бачимо, що дані на всіх графіках близькі до нормального розподілу.

#----------------------------------------------------------------------------------------------------------------

# Тест Шапіро-Вілька на нормальність

shapiro.test(mod$residuals)

# Shapiro-Wilk normality test
# 
# data:  mod$residuals
# W = 0.97419, p-value = 0.4069

# Null hypothesis: The data is normally distributed. If p> 0.05, normality can be assumed.
# For the approximately normally distributed data,
# p = 0.4069 so the
# null hypothesis is retained at the 95% level of significance.
# Therefore, normality can be assumed
# for this data set

shapiro.test(mod_better$residuals)
# data:  mod_better$residuals
# W = 0.96067, p-value = 0.1295

# p = 0.1295
# Therefore, normality can be assumed
# for this data set

shapiro.test(mod_better1$residuals)
# data:  mod_better1$residuals
# W = 0.96791, p-value = 0.2428

# p-value = 0.2428, so normality can be assumed
# for this data set

shapiro.test(modBIC1$residuals)
# data:  modBIC1$residuals
# W = 0.9745, p-value = 0.4167

# p-value = 0.4167, so normality can be assumed
# for this data set

#Тобто, бачимо, що у всіх 4-х моделях,
#спостерігається нормальний розподіл
#А найбільш нормально розподілені дані в modBIC1
# де p-value = 0.4167 (найбільше)

#----------------------------------------------------------------------------------------------------------------

# Тест Ліллієфорса - пристосування Колмогорова-Смірнова для перевірки нормальності

nortest::lillie.test(mod$residuals)

# Lilliefors (Kolmogorov-Smirnov) normality test
# 
# data:  mod$residuals
# D = 0.12636, p-value = 0.06907

# Ми не відкидаємо нормальності

nortest::lillie.test(mod_better$residuals)
# data:  mod_better$residuals
# D = 0.13602, p-value = 0.03608

# Вище тест показав, що дані не зовсім нормально розподілені, проте
# показник все ще достатньо високий

nortest::lillie.test(mod_better1$residuals)
# data:  mod_better1$residuals
# D = 0.10459, p-value = 0.2496

nortest::lillie.test(modBIC1$residuals)
# data:  modBIC1$residuals
# D = 0.10651, p-value = 0.226

# Висновок: 
# Відхилення нормальні
# Всі найкращі моделі розподілені нормально, тому
# перетворення Бокса-Кокса тут не потрібне.
# згідно з графіками та результатами тестів, дані близькі до нормального розподілу.

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

## Завдання (C)
# Перевірити дані на гомоскедастичність. 
# Представити графічно plot(*, 3). 
# Для перевірки використати тест Брейша – Пагана.

#----------------------------------------------------------------------------------------------------------------

par(mfrow = c(1, 1))
plot(mod, 3)
plot(mod_better, 3)
plot(mod_better1, 3)
plot(modBIC1, 3)

# За графіками, дані розподілені гомоскедастично

#----------------------------------------------------------------------------------------------------------------

# Тест Брейша-Пагана

car::ncvTest(mod)

# Non-constant Variance Score Test 
# Variance formula: ~ fitted.values 
# Chisquare = 0.6657799, Df = 1, p = 0.41453

bptest(mod)

# studentized Breusch-Pagan test
# 
# data:  mod
# BP = 3.676, df = 5, p-value = 0.5969

# Тут ми не відкидаємо гіпотезу про гомоскедастичність
# бо маємо великий p-value

car::ncvTest(mod_better)
# Chisquare = 1.392283, Df = 1, p = 0.23802
bptest(mod_better)
# data:  mod_better
# BP = 2.3527, df = 5, p-value = 0.7985

car::ncvTest(mod_better1)
# Chisquare = 0.283447, Df = 1, p = 0.59445
bptest(mod_better1)
# data:  mod_better
# BP = 2.7695, df = 4, p-value = 0.5971

car::ncvTest(modBIC)
# Chisquare = 0.003987271, Df = 1, p = 0.94965
bptest(modBIC)
# data:  mod_better
# BP = 1.4365, df = 3, p-value = 0.697

#Висновок: 
# Аналізуючи графік та результати тестів - 
# дані гомоскедастичні у всіх 4-х моделях

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

## Завдання (D)
# Перевірити дані на незалежність. 
# Представити графічно plot(*$residuals, type = "o").
# Для перевірки використати тест Дарбiна – Ватсона.

#----------------------------------------------------------------------------------------------------------------

par(mfrow = c(1, 1))
plot(mod$residuals, type = "o") 
plot(mod_better$residuals, type = "o") 
plot(mod_better1$residuals, type = "o") 
plot(modBIC$residuals, type = "o") 

# Всі моделі приблизно однаково поводять себе на графіку

#----------------------------------------------------------------------------------------------------------------

lag.plot(mod$residuals, lags = 1, do.lines = FALSE)
lag.plot(mod_better$residuals, lags = 1, do.lines = FALSE)
lag.plot(mod_better1$residuals, lags = 1, do.lines = FALSE)
lag.plot(modBIC$residuals, lags = 1, do.lines = FALSE)

# Немає серйозних серійних тенденцій, незалежність явно виражена
# автокореляція позитивна і незначна

cor(mod$residuals[-1], mod$residuals[-length(mod$residuals)])
# 0.07053332
cor(mod_better$residuals[-1], mod_better$residuals[-length(mod_better$residuals)])
# 0.08278622
cor(mod_better1$residuals[-1], mod_better1$residuals[-length(mod_better1$residuals)])
# 0.08214831
cor(modBIC$residuals[-1], modBIC$residuals[-length(modBIC$residuals)])
# 0.0703391

#----------------------------------------------------------------------------------------------------------------

# Тест Дарбiна – Ватсона
car::durbinWatsonTest(mod)
# lag Autocorrelation D-W Statistic p-value
# 1       0.0704407      1.856432   0.538
# Alternative hypothesis: rho != 0

#За p-value не відкидається (оскільки 0.538 > 0.05)

#----------------------------------------------------------------------------------------------------------------

car::durbinWatsonTest(mod_better)
# lag Autocorrelation D-W Statistic p-value
# 1      0.08266393      1.830988   0.578
# Alternative hypothesis: rho != 0

#----------------------------------------------------------------------------------------------------------------

car::durbinWatsonTest(mod_better1)
# lag Autocorrelation D-W Statistic p-value
# 1      0.08206205      1.833094   0.608
# Alternative hypothesis: rho != 0

#----------------------------------------------------------------------------------------------------------------

car::durbinWatsonTest(modBIC)
# lag Autocorrelation D-W Statistic p-value
# 1       0.0702217      1.855724    0.62
# Alternative hypothesis: rho != 0

#Висновок: згідно з графіком та результатами тестів - дані не є залежними 

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

# Завдання (E)
# Перевірити дані на мультиколінеарність. Представити залежність таблично та
# графічно. За допомогою обчислення коефіцієнта Variance Inflation Factor (VIF)
# перевірити предиктори на мультиколінеарність;

round(cor(baseball), 2)
#             Y    X1    X2    X3    X4    X5     y    y1 
# Y        1.00  0.82  0.61  0.66  0.31 -0.65  1.00  1.00
# X1       0.82  1.00  0.52  0.60  0.49 -0.35  0.82  0.82
# X2       0.61  0.52  1.00  0.49  0.28 -0.26  0.58  0.60
# X3       0.66  0.60  0.49  1.00 -0.05 -0.50  0.64  0.65
# X4       0.31  0.49  0.28 -0.05  1.00  0.17  0.33  0.32
# X5      -0.65 -0.35 -0.26 -0.50  0.17  1.00 -0.66 -0.66
# y        1.00  0.82  0.58  0.64  0.33 -0.66  1.00  1.00
# y1       1.00  0.82  0.60  0.65  0.32 -0.66  1.00  1.00

#----------------------------------------------------------------------------------------------------------------

# Графічно
corrplot::corrplot(cor(baseball), addCoef.col = "grey")

# За графіком бачимо, що
# X4 можна взагалі прибрати, її вплив незначний
# X3 корелює з X5, проте це не дуже значний показник

#----------------------------------------------------------------------------------------------------------------

car::vif(mod)
#     X1       X2       X3       X4       X5 
# 2.981580 1.521391 2.409549 2.015880 1.477788 

# Як такої мультиколінеарності немає, бо всі параметри <5

#----------------------------------------------------------------------------------------------------------------

# Аномальна variance inflation factors: найбільша для x1
# Проте, її видалення не призведе до чогось хорошого

mod_v <- lm(Y~X2+X3+X4+X5,data = baseball)
summary(mod_v)
# Multiple R-squared:  0.7815,	Adjusted R-squared:  0.7596 
# F-statistic: 35.76 on 4 and 40 DF,  p-value: 1.026e-12

#Як бачимо F-statistic різко впала

#----------------------------------------------------------------------------------------------------------------

# Перша початкова модель
summary(mod)
# Multiple R-squared:  0.8646,	Adjusted R-squared:  0.8472 
# F-statistic:  49.8 on 5 and 39 DF,  p-value: 6.75e-16

#----------------------------------------------------------------------------------------------------------------

# Наступною можна відкинути X3, так як 
# аномальна variance inflation factors теж висока

mod_v1 <- lm(Y~X1+X2+X4+X5,data = baseball)
summary(mod_v1)
# Multiple R-squared:  0.8623,	Adjusted R-squared:  0.8485 
# F-statistic: 62.63 on 4 and 40 DF,  p-value: < 2.2e-16

#----------------------------------------------------------------------------------------------------------------

#Як бачимо, ситуація одразу значно покращилася,
#якщо поглянути на F-statistic початкової моделі та отриманої

#Тепер спробуємо відкинути ще X4

mod_v2 <- lm(Y~X1+X2+X5,data = baseball)
summary(mod_v2)
# Multiple R-squared:  0.8602,	Adjusted R-squared:  0.8499 
# F-statistic: 84.06 on 3 and 41 DF,  p-value: < 2.2e-16

#----------------------------------------------------------------------------------------------------------------

# Тепер показник F-statistic значно покращився, порівняно з F-statistic:  49.8 
# для початкової моделі

car::vif(mod_v2)
# X1       X2       X5 
# 1.466568 1.378695 1.154163
# Variance inflation factors нормальні

#----------------------------------------------------------------------------------------------------------------

# Порівняння
car::compareCoefs(mod, mod_v2)
# Calls:
# 1: lm(formula = Y ~ ., data = baseball)
# 2: lm(formula = Y ~ . - X4 - X3, data = baseball)
# 
#               Model 1 Model 2
# (Intercept)  0.1874  0.1791
# SE           0.0173  0.0153
# 
# X1           0.5214  0.6069
# SE           0.1066  0.0741
# 
# X2            0.776   0.867
# SE            0.306   0.289
# 
# X3            0.469        
# SE            0.578        
# 
# X4            0.180        
# SE            0.169        
# 
# X5          -0.2919 -0.2828
# SE           0.0515  0.0451

# Бачимо, що показники кращі в другій моделі

#----------------------------------------------------------------------------------------------------------------

# Довірчі інтервали
confint(mod)
#                 2.5 %     97.5 %
#(Intercept)   0.1524659  0.2224071
# X1           0.3058658  0.7369968
# X2           0.1570667  1.3949138
# X3          -0.7011720  1.6382239
# X4          -0.1621918  0.5212954
# X5          -0.3960627 -0.1877831

#----------------------------------------------------------------------------------------------------------------

confint(mod_v2)
#                 2.5 %     97.5 %
# (Intercept)  0.1481215  0.2100223
# X1           0.4572645  0.7564904
# X2           0.2844265  1.4505449
# X5          -0.3739116 -0.1917587

#----------------------------------------------------------------------------------------------------------------

# Висновок: перевірили дані на мультиколінеарність
# модель покращилася, коли відкинули X4,X3
# Variance inflation factors нормальні

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

# Завдання (F)
# Перевірити на наявність аномальних чи високоефективних точок. Представити
# графічно plot(*, 5).

plot(mod, 5)
plot(mod_better1, 5)
plot(mod_v2, 5)

# Графіки не показали ніяких 
# аномальних точок

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

# Висновок:
# Проведена модельна діагностика кейсу показала,
# що найвагомішими параметрами, які найбільше впливають
# на batting average конкретного бейсбольного гравця,
# є X1 = runs scored/times at bat, X2 = doubles/times at bat
# та X5 = strike outs/times at bat.
# Дані є гомоскедастичними, нормально розподіленими.
# Аномальних чи високоефективних точок не було виявлено.

#----------------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------------

